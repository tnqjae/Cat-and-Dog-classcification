{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ufdRf-E-0IDj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHagGz0wAJ7"
      },
      "source": [
        "<h1>Data transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0WuGaERJ0NAT"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG-16 ÏûÖÎ†• ÌÅ¨Í∏∞\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet Ï†ïÍ∑úÌôî\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Hp_0fqUPwuY0"
      },
      "outputs": [],
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú (ÏòàÏ†úÏóêÏÑúÎäî ImageFolder ÏÇ¨Ïö©)\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='./dataset/training_set/training_set', transform=transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='./dataset/test_set/test_set', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-3IZbWYRwvXE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # Conv Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 1),  # üîπ 2Í∞ú ÌÅ¥ÎûòÏä§ ‚Üí 1Í∞ú Ï∂úÎ†• ÎÖ∏Îìú\n",
        "            nn.Sigmoid()  # üîπ Ïù¥ÏßÑ Î∂ÑÎ•òÎ•º ÏúÑÌïú Sigmoid Ï∂îÍ∞Ä\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x  # Sigmoid Í∞í Ï∂úÎ†• (0~1 ÏÇ¨Ïù¥ ÌôïÎ•†Í∞í)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yssYhts6ySRn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tnqja\\anaconda3\\envs\\AI\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\tnqja\\anaconda3\\envs\\AI\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\tnqja/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528M/528M [00:09<00:00, 57.0MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.0619\n",
            "Epoch [2/20], Loss: 0.0126\n",
            "Epoch [3/20], Loss: 0.0077\n",
            "Epoch [4/20], Loss: 0.0069\n",
            "Epoch [5/20], Loss: 0.0108\n",
            "Epoch [6/20], Loss: 0.0106\n",
            "Epoch [7/20], Loss: 0.0246\n",
            "Epoch [8/20], Loss: 0.0175\n",
            "Epoch [9/20], Loss: 0.0073\n",
            "Epoch [10/20], Loss: 0.0064\n",
            "Epoch [11/20], Loss: 0.0048\n",
            "Epoch [12/20], Loss: 0.0025\n",
            "Epoch [13/20], Loss: 0.0056\n",
            "Epoch [14/20], Loss: 0.0125\n",
            "Epoch [15/20], Loss: 0.0066\n",
            "Epoch [16/20], Loss: 0.0162\n",
            "Epoch [17/20], Loss: 0.0137\n",
            "Epoch [18/20], Loss: 0.0058\n",
            "Epoch [19/20], Loss: 0.0018\n",
            "Epoch [20/20], Loss: 0.0116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# ‚úÖ VGG-16 Î™®Îç∏ ÏàòÏ†ï (Ï∂úÎ†•Ï∏µ: 1Í∞ú ÎÖ∏Îìú, Sigmoid ÌïÑÏöî)\n",
        "class VGG16Binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16Binary, self).__init__()\n",
        "        self.vgg16 = models.vgg16(pretrained=True)  # Pretrained VGG-16 Î∂àÎü¨Ïò§Í∏∞\n",
        "\n",
        "        # üîπ Feature Extractor (Conv Layers) Í≥†Ï†ï (Fine-tuning)\n",
        "        for param in self.vgg16.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # üîπ Fully Connected Layer ÏàòÏ†ï (Ï∂úÎ†•Ï∏µ 1Í∞ú ‚Üí Sigmoid ÏÇ¨Ïö©)\n",
        "        self.vgg16.classifier[6] = nn.Linear(4096, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg16(x)  # Sigmoid ÏóÜÏù¥ logits Ï∂úÎ†•\n",
        "\n",
        "# ‚úÖ Î™®Îç∏ ÏÉùÏÑ±\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VGG16Binary().to(device)\n",
        "\n",
        "# ‚úÖ ÏÜêÏã§ Ìï®Ïàò Î≥ÄÍ≤Ω (CrossEntropyLoss ‚Üí BCEWithLogitsLoss)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # ÌïôÏäµÎ•† ÎÇÆÏ∂§\n",
        "\n",
        "# ‚úÖ ÌïôÏäµ Í≥ºÏ†ï\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # üîπ Float Î≥ÄÌôò Î∞è Ï∞®Ïõê Î≥ÄÍ≤Ω\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)  # Logits Í∞í Ï∂úÎ†•\n",
        "        loss = criterion(outputs, labels)  # ÏÜêÏã§ Í≥ÑÏÇ∞\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.5051\n",
            "Validation Accuracy: 97.92%\n",
            "F1 Score: 0.9796\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "\n",
        "# ‚úÖ Î™®Îç∏ÏùÑ ÌèâÍ∞Ä Î™®ÎìúÎ°ú Î≥ÄÍ≤Ω\n",
        "model.eval()\n",
        "\n",
        "# ‚úÖ Í≤ÄÏ¶ù(Validation) Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0\n",
        "\n",
        "# ‚úÖ Precision, Recall, F1 Score Í≥ÑÏÇ∞ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "# ÏÜêÏã§ Ìï®Ïàò Ï†ïÏùò (BCEWithLogitsLoss ÏÇ¨Ïö©)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # üîπ Float Î≥ÄÌôò\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)  # üîπ ÏÜêÏã§ Í≥ÑÏÇ∞\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5  # üîπ 0.5 Ïù¥ÏÉÅÏù¥Î©¥ 1(Í∞ïÏïÑÏßÄ), ÏïÑÎãàÎ©¥ 0(Í≥†ÏñëÏù¥)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Î¶¨Ïä§Ìä∏Ïóê Ï∂îÍ∞Ä\n",
        "        all_labels.append(labels)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "# ‚úÖ Ï†ïÌôïÎèÑ(Accuracy) Í≥ÑÏÇ∞\n",
        "accuracy = 100 * correct / total\n",
        "avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# ‚úÖ F1 Score Í≥ÑÏÇ∞ (PyTorch Metrics ÏÇ¨Ïö©)\n",
        "f1_metric = BinaryF1Score().to(device)\n",
        "f1 = f1_metric(torch.cat(all_preds), torch.cat(all_labels))\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Î™®Îç∏ ÌÖåÏä§Ìä∏\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# ‚úÖ Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (VGG-16Ïóê ÎßûÍ≤å Î≥ÄÌôò)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG-16 ÏûÖÎ†• ÌÅ¨Í∏∞\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet Ï†ïÍ∑úÌôî\n",
        "])\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌïòÍ≥† VGG-16 ÏûÖÎ†• ÌòïÌÉúÎ°ú Î≥ÄÌôò\"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Ïù¥ÎØ∏ÏßÄÎ•º RGB Î™®ÎìúÎ°ú Î≥ÄÌôò\n",
        "    image = transform(image)  # Î≥ÄÌôò Ï†ÅÏö©\n",
        "    image = image.unsqueeze(0)  # Î∞∞Ïπò Ï∞®Ïõê Ï∂îÍ∞Ä (Î™®Îç∏ÏùÄ [batch, C, H, W] ÌòïÌÉú ÏûÖÎ†• ÌïÑÏöî)\n",
        "    return image.to(device)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_image(model, image_path):\n",
        "    \"\"\"Ïù¥ÎØ∏ÏßÄÎ•º ÏûÖÎ†•Î∞õÏïÑ Î™®Îç∏Ïù¥ Í∞ïÏïÑÏßÄ/Í≥†ÏñëÏù¥ ÏòàÏ∏°\"\"\"\n",
        "    model.eval()  # Î™®Îç∏ÏùÑ ÌèâÍ∞Ä Î™®ÎìúÎ°ú ÏÑ§Ï†ï\n",
        "    image = preprocess_image(image_path)  # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        probability = torch.sigmoid(output).item()  # ÌôïÎ•†Í∞í Î≥ÄÌôò (Sigmoid Ï†ÅÏö©)\n",
        "        prediction = \"Dog üê∂\" if probability > 0.5 else \"Cat üê±\"\n",
        "    \n",
        "    print(f\"Image: {image_path} | Predicted: {prediction} | Probability: {probability:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_image(\u001b[43mmodel\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dataset/input/dog1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "predict_image(model, \"./dataset/input/dog1.jpg\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ‚úÖ Î™®Îç∏ ÌïôÏäµ ÌõÑ Ï†ÄÏû• (ÏòàÏ†úÏóêÏÑúÎäî ÌïôÏäµÏù¥ ÏôÑÎ£åÎêú ÏÉÅÌÉúÎùºÍ≥† Í∞ÄÏ†ï)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict()}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Î™®Îç∏Ïù¥ model.pth ÌååÏùºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# ‚úÖ Î™®Îç∏ ÌïôÏäµ ÌõÑ Ï†ÄÏû• (ÏòàÏ†úÏóêÏÑúÎäî ÌïôÏäµÏù¥ ÏôÑÎ£åÎêú ÏÉÅÌÉúÎùºÍ≥† Í∞ÄÏ†ï)\n",
        "torch.save(model.state_dict(), \"model.pth\")  # üîπ ÌïôÏäµÎêú Í∞ÄÏ§ëÏπòÎßå Ï†ÄÏû•\n",
        "\n",
        "print(\"‚úÖ Î™®Îç∏Ïù¥ model.pth ÌååÏùºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (1.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from flask) (8.0.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from importlib-metadata>=3.6.0->flask) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tnqja\\anaconda3\\envs\\ai\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
